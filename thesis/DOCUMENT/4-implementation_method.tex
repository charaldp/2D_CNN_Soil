\chapter{Μέθοδος υλοποίησης}
\label{ch:implementation_method}

\section{Προτεινόμενη υλοποίηση}
Η υλοποίηση που προτείνεται στο άρθρο του \tl{Padarian J.}\cite{padarian_lucas_soil} αναφέρει πως δεν τροποποιεί την είσοδο στα αρχικά δεδομένα. Αυτό έχει ως αποτέλεσμα η εικόνα που προκύπτει στην είσοδο του συνελικτικού νευρωνικού δικτύου να είναι σχετικά μεγάλη. Επίσης η αρχιτεκτονική περιλαμβάνει ένα μεγάλο πλήθος επιπέδων. Ο συνδυασμός των 2 παραπάνω καθιστά την εκπαίδευση του μοντέλου ιδιαίτερα κοστοβόρα λόγω του μεγάλου πλήθους παραμέτρων.

Ένα επιπλέον λάθος που παρατηρείται στην συγκεκριμένη ανάλθση είναι η χρήση 

Η υλοποίηση θα μπορούσε να τροποποιηθεί...

\section{Υποδειγματοληψία φάσματος εισόδου --- αποτελεσματικότητα με ελαχιστοποίηση μεγέθους μοντέλου}

\section{Μέθοδοι επίβλεψης της εκπαίδευσης του μοντέλου}

\subsection{Απόκλιση του σφάλματος \tl{validation} κατά την εκπαίδευση}

\subsection{Επαναρχικοποίηση εκπαίδευσης σε περίπτωση ακατάλληλων βαρών}

\subsection{\tl{Checkpoint} μοντέλου κατά την εκπαίδευση}
Ανάκτηση βέλτιστων παραμέτρων με βάση τον σφάλμα \tl{validation}

\subsection{Παραμέτροι εκπαίδευσης}
Κατάλληλος αριθμός εποχών, \tl{Batch-Size}

\subsection{Μέθοδος κ-πλης διασταυρωμένης επικύρωσης}
Κατά την εκπαίδευση των μοντέλων πάνω στο σετ δεδομένων είναι επιθυμητό να εξαλειφθεί ο παράγοντας της τυχαιότητας στον τρόπο της τελικής μορφής ενός μοντέλου και της απόδοσης του, ώστε τα τελικά αποτελέσματα να μπορούν να θεωρηθούν βάσιμα.
Οι παράγοντες οι οποίοι μπορούν να μειώσουν την τυχαιότητα και να οδηγήσουν σε ένα γενικευμένο αποτέλεσμα σε κάθε εκτέλεση του πειράματος είναι, ο αριθμός των επαναλήψεων των υπο-πειραμάτων και ο διαχωρισμός των δεδομένων σε τμήματα εκπαίδευσης--επικύρωσης--αξιολόγησης με όσο το δυνατόν διαφορετικές δομές.
Μια από τις μεθόδους επίτευξης των παραπάνω είναι η διασταυρωμένη επικύρωση. Κατά την χρήση της συγκεκριμένης μεθόδου το αρχικό σετ δεδομένων χωρίζεται σε 2 μέρη, τα δεδομένα εκπαίδευσης-επικύρωσης και τα δεδομένα αξιολόγησης τα οποία χρησιμοποιούνται έπειτα από την διαδικασία εκπαίδευσης. Τα 2 αυτά μέρη είναι χωρισμένα με ποσοστά πτυχών 60 -- 40 \% με περίπου 12000 από τα 19000 δείγματα. Το μέρος εκπαίδευσης-επικύρωσης του σετ δεδομένων χωρίζεται στα επιμέρους τμήματα του σε ποσοστά 80 -- 20 \% αντίστοιχα, με περίπου 9566 και 2392 δείγματα.
Η διαδικασία διαχωρισμού των τμημάτων εκπαίδευσης-επικύρωσης του σετ δεδομένων επαναλαμβάνεται χρησιμοποιώντας κάθε φορά μια διαφορετική από τις 5 πτυχές διαχωρισμού ως το σετ επικύρωσης.

Αυτό που επιτυγχάνεται ουσιαστικά είναι η εξαγωγή μετρικών με τη χρήση των προβλέψεων 5 διαφορετικών μοντέλων

\section{Τροποποίηση αρχιτεκτονικής προτεινόμενου μοντέλου}

\section{Μοντέλο μιας εισόδου -- μιας εξόδου}

\section{Μοντέλο πολλαπλών εξόδων}

\section{Μοντέλο πολλαπλών εισόδων -- εξόδων}

\section{Μοντέλο πολλαπλών εισόδων -- μιας εξόδου}

\section{Υλοποίηση εξαγωγή \tl{Absorbances--Savintzky Golay} 1η παράγωγος από \tl{Reflectances}}

\section{Κανονικοποίηση δεδομένων εισόδου -- εξόδου}

\subsection{Κανονικοποίηση εισόδου}

\subsection{Κανονικοποίηση εξόδου}
