\chapter{Μέθοδος υλοποίησης}
\label{ch:implementation_method}

\section{Προτεινόμενη υλοποίηση}
Η υλοποίηση που προτείνεται στο άρθρο του \tl{Padarian J.}\cite{padarian_lucas_soil} αναφέρει πως δεν τροποποιεί την είσοδο στα αρχικά δεδομένα. Αυτό έχει ως αποτέλεσμα η εικόνα που προκύπτει στην είσοδο του συνελικτικού νευρωνικού δικτύου να είναι σχετικά μεγάλη. Επίσης η αρχιτεκτονική περιλαμβάνει ένα μεγάλο πλήθος επιπέδων. Ο συνδυασμός των 2 παραπάνω καθιστά την εκπαίδευση του μοντέλου ιδιαίτερα κοστοβόρα λόγω του μεγάλου πλήθους παραμέτρων.\\

Ένα επιπλέον λάθος που παρατηρείται στην συγκεκριμένη ανάλυση είναι η χρήση όλων των δειγμάτων της εδαφικής βάσης του \tl{LUCAS} συμπεριλαμβανομένων και των οργανικών δειγμάτων για ορισμένα από τα πειράματα. Αυτό οδηγεί στην εξαγωγή ορισμένων μετρικών όπως ο συντελεστής προσδιορισμού που δεν ανταποκρίνονται στην πραγματική επίδοση των μοντέλων για την ιδιότητα της περιεκτικότητας σε οργανικό άνθρακα. Το παραπάνω μπορεί να διαπιστωθεί μέσω της σύγκρισης με άλλες υλοποιήσεις με βάση την τιμή της ρίζας του μέσου τετραγωνικού σφάλματος.\\

Η υλοποίηση θα μπορούσε να τροποποιηθεί ώστε 

\section{Εργαλεία υλοποίησης}
Η ανάπτυξη των μοντέλων βαθιάς μηχανικής μάθησης και συνελικτικών νευρωνικών δικτύων έγινε στη γλώσσα \tl{Python} και με τη χρήση των σχετικών βιβλιοθηκών \tl{Tensorflow\cite{tensorflow} - Keras\cite{keras}} για το \tl{Backend} και το \tl{Frontend} αντίστοιχα για το περιβάλλον ανάπτυξης του κώδικα.

\section{Αρχιτεκτονική νευρωνικού δικτύου}
Το βήμα συνέλιξης είναι μονάδα έτσι η εικόνα εξόδου έχει ίδιες διαστάσεις με την εικόνα εισόδου στα επίπεδα της συνέλιξης

\section{Υποδειγματοληψία φάσματος εισόδου --- αποτελεσματικότητα με ελαχιστοποίηση μεγέθους μοντέλου}
Κατά την εισαγωγή των δεδομένων του φάσματος κάθε εγγραφής εφαρμόστηκε μια μέθοδος κατά την οποία με τη χρήση μιας παραμέτρου υποδειγματοληψίας \tl{(Undersampling)} η οποία έχει συνεχείς τιμές μεγαλύτερες της μονάδας. Με βάση αυτή την παράμετρο το φάσμα εισόδου δειγματοληπτείται ... ή με τη χρήση γραμμικής παρεμβολής με τη βοήθεια της συνάρτησης \tl{interp} της βιβλιοθήκης \tl{numpy} το φάσμα υποδειγματοληπτείται ανά $k$ φορές. Έτσι η είσοδος που προκύπτει έχει μέγεθος $\lfloor\frac{n}{k}\rfloor$. Όπου $n$ το πλήθος των δειγμάτων του φάσματος (συνήθως 4200), ενώ $k$ ο συντελεστής υποδειγματοληψίας με $k\ge1$.\\
Η επιλογή της συγκεκριμένης παραμέτρου παρατηρήθηκε πως έχει μεγάλη επιρροή στην αποτελεσματικότητα των μοντέλων ...
\section{Μέθοδοι επίβλεψης της εκπαίδευσης του μοντέλου}

\subsection{Απόκλιση του σφάλματος \tl{validation} κατά την εκπαίδευση}

\subsection{Επαναρχικοποίηση εκπαίδευσης σε περίπτωση ακατάλληλων βαρών}

\subsection{\tl{Checkpoint} μοντέλου κατά την εκπαίδευση}
Ανάκτηση βέλτιστων παραμέτρων με βάση τον σφάλμα \tl{validation}

\subsection{Παραμέτροι εκπαίδευσης}
Κατάλληλος αριθμός εποχών, \tl{Batch-Size}

\subsection{Μέθοδος κ-πλης διασταυρωμένης επικύρωσης}
Κατά την εκπαίδευση των μοντέλων πάνω στο σετ δεδομένων είναι επιθυμητό να εξαλειφθεί ο παράγοντας της τυχαιότητας στον τρόπο της τελικής μορφής ενός μοντέλου και της απόδοσης του, ώστε τα τελικά αποτελέσματα να μπορούν να θεωρηθούν βάσιμα.
Οι παράγοντες οι οποίοι μπορούν να μειώσουν την τυχαιότητα και να οδηγήσουν σε ένα γενικευμένο αποτέλεσμα σε κάθε εκτέλεση του πειράματος είναι, ο αριθμός των επαναλήψεων των υπο-πειραμάτων και ο διαχωρισμός των δεδομένων σε τμήματα εκπαίδευσης--επικύρωσης--αξιολόγησης με όσο το δυνατόν διαφορετικές δομές.
Μια από τις μεθόδους επίτευξης των παραπάνω είναι η διασταυρωμένη επικύρωση. Κατά την χρήση της συγκεκριμένης μεθόδου το αρχικό σετ δεδομένων χωρίζεται σε 2 μέρη, τα δεδομένα εκπαίδευσης-επικύρωσης και τα δεδομένα αξιολόγησης τα οποία χρησιμοποιούνται έπειτα από την διαδικασία εκπαίδευσης. Τα 2 αυτά μέρη είναι χωρισμένα με ποσοστά πτυχών 60 -- 40 \% με περίπου 12000 από τα 19000 δείγματα. Το μέρος εκπαίδευσης-επικύρωσης του σετ δεδομένων χωρίζεται στα επιμέρους τμήματα του σε ποσοστά 80 -- 20 \% αντίστοιχα, με περίπου 9566 και 2392 δείγματα.
Η διαδικασία διαχωρισμού των τμημάτων εκπαίδευσης-επικύρωσης του σετ δεδομένων επαναλαμβάνεται χρησιμοποιώντας κάθε φορά μια διαφορετική από τις 5 πτυχές διαχωρισμού ως το σετ επικύρωσης.

Αυτό που επιτυγχάνεται ουσιαστικά είναι η εξαγωγή μετρικών με τη χρήση των προβλέψεων 5 διαφορετικών μοντέλων

\section{Τροποποίηση αρχιτεκτονικής προτεινόμενου μοντέλου}

\section{Μοντέλο μιας εισόδου -- μιας εξόδου}

\section{Μοντέλο πολλαπλών εξόδων}

\section{Μοντέλο πολλαπλών εισόδων -- εξόδων}

\section{Μοντέλο πολλαπλών εισόδων -- μιας εξόδου}

\section{Υλοποίηση εξαγωγής \tl{Absorbances--Savintzky Golay} 1η παράγωγος από \tl{Reflectances}}

\section{Κανονικοποίηση δεδομένων εισόδου -- εξόδου}

\subsection{Κανονικοποίηση εισόδου}

\subsection{Κανονικοποίηση εξόδου}
